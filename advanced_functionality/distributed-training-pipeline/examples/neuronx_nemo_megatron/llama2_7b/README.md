# Pre-train Llama2 7B on Redpajama dataset using Neuronx-Nemo-Megatron

This example shows how to pre-train Llama2-7B model on [Redpajama dataset](https://github.com/togethercomputer/RedPajama-Data) with [Neuronx-Nemo-Megatron](https://github.com/aws-neuron/neuronx-nemo-megatron). 
